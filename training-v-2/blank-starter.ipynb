{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\r\n",
      "Requirement already satisfied: torch==1.5.0+cpu in /opt/conda/lib/python3.8/site-packages (1.5.0+cpu)\r\n",
      "Requirement already satisfied: torchvision==0.6.0+cpu in /opt/conda/lib/python3.8/site-packages (0.6.0+cpu)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.8/site-packages (from torch==1.5.0+cpu) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torch==1.5.0+cpu) (1.19.2)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from torchvision==0.6.0+cpu) (8.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install jovian --upgrade --quiet\n",
    "!pip install torch==1.5.0+cpu torchvision==0.6.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], \n",
    "                   [10, 11, 12], [13, 14, 15], [16, 17, 18], \n",
    "                   [19, 20, 21], [22, 23, 24], [25, 26, 27], \n",
    "                   [28, 29, 30], [31, 32, 33], [34, 35, 36], \n",
    "                   [87, 134, 58], [102, 43, 37], [69, 96, 70]], \n",
    "                  dtype='float32')\n",
    "targets = np.array([[56, 70], [81, 101], [119, 133], \n",
    "                    [22, 37], [103, 119], [56, 70], \n",
    "                    [81, 101], [119, 133], [22, 37], \n",
    "                    [103, 119], [56, 70], [81, 101], \n",
    "                    [119, 133], [22, 37], [103, 119]], \n",
    "                   dtype='float32')\n",
    "inputs=torch.from_numpy(inputs)\n",
    "targets=torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   2.,   3.],\n",
       "        [  4.,   5.,   6.],\n",
       "        [  7.,   8.,   9.],\n",
       "        [ 10.,  11.,  12.],\n",
       "        [ 13.,  14.,  15.],\n",
       "        [ 16.,  17.,  18.],\n",
       "        [ 19.,  20.,  21.],\n",
       "        [ 22.,  23.,  24.],\n",
       "        [ 25.,  26.,  27.],\n",
       "        [ 28.,  29.,  30.],\n",
       "        [ 31.,  32.,  33.],\n",
       "        [ 34.,  35.,  36.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#you can list it 1,2,3 there is a 0 too\n",
    "#the : is from x to y x:y\n",
    "train_ds=TensorDataset(inputs,targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the dataloader\n",
    "#the data loader can slpit the data into batches while training.It can also shuffle and random sampling the data\n",
    "batch_size=5\n",
    "train_dl= DataLoader(train_ds,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[102.,  43.,  37.],\n",
      "        [ 10.,  11.,  12.],\n",
      "        [ 69.,  96.,  70.],\n",
      "        [ 28.,  29.,  30.],\n",
      "        [  4.,   5.,   6.]])\n",
      "tensor([[ 22.,  37.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.],\n",
      "        [103., 119.],\n",
      "        [ 81., 101.]])\n",
      "tensor([[34., 35., 36.],\n",
      "        [13., 14., 15.],\n",
      "        [19., 20., 21.],\n",
      "        [25., 26., 27.],\n",
      "        [ 7.,  8.,  9.]])\n",
      "tensor([[ 81., 101.],\n",
      "        [103., 119.],\n",
      "        [ 81., 101.],\n",
      "        [ 22.,  37.],\n",
      "        [119., 133.]])\n",
      "tensor([[ 22.,  23.,  24.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [ 31.,  32.,  33.],\n",
      "        [ 16.,  17.,  18.],\n",
      "        [  1.,   2.,   3.]])\n",
      "tensor([[119., 133.],\n",
      "        [119., 133.],\n",
      "        [ 56.,  70.],\n",
      "        [ 56.,  70.],\n",
      "        [ 56.,  70.]])\n"
     ]
    }
   ],
   "source": [
    "#the shuffleing is taking the batch[]you choose and shuffling it based on the amount on each batch.\n",
    "#train_ds is all of the input and targets batch size is how many [] in each batch and shuffle is shuffling together\n",
    "for xb,yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5612, -0.4916, -0.0431],\n",
      "        [ 0.1227,  0.1007,  0.1877]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3763, -0.1804], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#the bias weights and bias determines if the neuron in the next layer is activated.Indicates how strong of the connection\n",
    "#is between two nerons in seperate layers\n",
    "#The bias is constant and the weight is constanlty changing\n",
    "#a high weight will transfer to the enxt neron and a low weight will not\n",
    "#the bias is another hidden layer you add to the final weights\n",
    "#cloums then rows\n",
    "#nice syntax for generating weights and biases these are the things we adjust to our model to make it better\n",
    "model=nn.Linear(3,2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -2.0501,    0.7068],\n",
       "        [  -5.3381,    1.9400],\n",
       "        [  -8.6261,    3.1733],\n",
       "        [ -11.9141,    4.4065],\n",
       "        [ -15.2020,    5.6398],\n",
       "        [ -18.4900,    6.8731],\n",
       "        [ -21.7780,    8.1063],\n",
       "        [ -25.0659,    9.3396],\n",
       "        [ -28.3539,   10.5729],\n",
       "        [ -31.6419,   11.8061],\n",
       "        [ -34.9299,   13.0394],\n",
       "        [ -38.2178,   14.2727],\n",
       "        [-117.5847,   34.8728],\n",
       "        [ -80.3585,   23.6087],\n",
       "        [ -89.3171,   31.0909]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the nice syntax for the loss function \n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=f.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11315.3916, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss=loss_fn(preds,targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is better syntax for optimizing the biases and wieghts\n",
    "#the model is from defined previoulsy already as the weights and biases \n",
    "opt=torch.optim.SGD(model.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for xb,yb in train_dl:\n",
    "            preds=model(xb)\n",
    "            loss=loss_fn(preds,yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1312.7859\n",
      "Epoch [20/100], Loss: 2179.6992\n",
      "Epoch [30/100], Loss: 3226.3923\n",
      "Epoch [40/100], Loss: 1357.3745\n",
      "Epoch [50/100], Loss: 1526.5081\n",
      "Epoch [60/100], Loss: 1197.8513\n",
      "Epoch [70/100], Loss: 1977.9055\n",
      "Epoch [80/100], Loss: 2293.2727\n",
      "Epoch [90/100], Loss: 1466.1487\n",
      "Epoch [100/100], Loss: 2244.7007\n"
     ]
    }
   ],
   "source": [
    "fit(100, model, loss_fn, opt,train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  8.9072,  10.8754],\n",
      "        [ 15.7539,  19.1435],\n",
      "        [ 22.6006,  27.4116],\n",
      "        [ 29.4473,  35.6796],\n",
      "        [ 36.2941,  43.9477],\n",
      "        [ 43.1408,  52.2158],\n",
      "        [ 49.9875,  60.4838],\n",
      "        [ 56.8342,  68.7519],\n",
      "        [ 63.6810,  77.0200],\n",
      "        [ 70.5277,  85.2880],\n",
      "        [ 77.3744,  93.5561],\n",
      "        [ 84.2211, 101.8242],\n",
      "        [102.4057, 113.6888],\n",
      "        [ 28.0691,  44.7594],\n",
      "        [159.1264, 186.9462]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "preds=model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.8651, -0.0676,  3.2150],\n",
      "        [-0.8630, -0.2859,  3.9049]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}